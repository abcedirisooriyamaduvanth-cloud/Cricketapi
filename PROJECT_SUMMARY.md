# Cricket Stream Scraper - Project Summary

## ğŸ¯ What Was Built

An automated cricket stream scraper that:
- Extracts m3u8 streaming links from cricket websites
- Captures network headers (Origin, Referer, User-Agent)
- Saves data to Firebase Realtime Database
- Runs automatically every 40 minutes via GitHub Actions
- Handles ads, redirects, and iframes

## ğŸ“ Project Structure

```
Cricketapi/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ scrape-streams.yml      # GitHub Actions workflow (40-min schedule)
â”œâ”€â”€ scraper_playwright.py           # Main scraper using Playwright
â”œâ”€â”€ quick_test.py                   # Firebase connection test
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore patterns
â”œâ”€â”€ README.md                       # Main documentation
â”œâ”€â”€ QUICKSTART.md                   # 5-minute setup guide
â”œâ”€â”€ TESTING.md                      # Testing instructions
â””â”€â”€ DEPLOYMENT.md                   # Deployment guide
```

## ğŸ”§ Technology Stack

- **Language**: Python 3.11
- **Browser Automation**: Playwright (Chromium)
- **Database**: Firebase Realtime Database
- **CI/CD**: GitHub Actions
- **Schedule**: Cron (every 40 minutes)

## ğŸŒŠ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GitHub Actions (Every 40 min)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              scraper_playwright.py                          â”‚
â”‚  1. Launch headless Chromium browser                        â”‚
â”‚  2. Navigate to cricket streaming site                      â”‚
â”‚  3. Handle iframes and redirects                            â”‚
â”‚  4. Capture network requests                                â”‚
â”‚  5. Extract m3u8 URLs + headers                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Firebase Realtime Database                     â”‚
â”‚  {                                                          â”‚
â”‚    "2ndserverlink": {                                       â”‚
â”‚      "link": "https://...m3u8",                             â”‚
â”‚      "headers": {...},                                      â”‚
â”‚      "status": "OK",                                        â”‚
â”‚      "createdAt": 1765715426393                             â”‚
â”‚    }                                                        â”‚
â”‚  }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Output Format

Each scraped stream is saved to Firebase with this structure:

```json
{
  "2ndserverlink": {
    "source_url": "https://crichdplayer.com/willow-cricket-extra-live-stream-play-01",
    "title": "Watch Stream Live Cricket on Willow Tv - CricHD",
    "name": "Willow Cricket Extra",
    "link": "https://d10.merichunidya.com:1686/hls/willowextra.m3u8?md5=...",
    "headers": {
      "Origin": "https://profamouslife.com",
      "Referer": "https://profamouslife.com/",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    },
    "status": "OK",
    "thumblink": "",
    "createdAt": 1765715426393,
    "createdAtISO": "2025-12-14T12:30:26Z",
    "lastCheckedAt": 1765715426393
  }
}
```

## âœ… Features

### Core Features
- âœ… Automated scraping every 40 minutes
- âœ… Headless browser automation with Playwright
- âœ… Network request interception for m3u8 detection
- âœ… Header extraction (Origin, Referer, User-Agent)
- âœ… Firebase RTDB integration
- âœ… Iframe and redirect handling
- âœ… Manual workflow trigger support

### Reliability Features
- âœ… Error handling and logging
- âœ… Artifact storage (7-day retention)
- âœ… Detailed debug output
- âœ… Multiple selector fallbacks for play buttons
- âœ… Configurable wait times

### Developer Features
- âœ… Local testing script (quick_test.py)
- âœ… Environment variable configuration
- âœ… Comprehensive documentation
- âœ… Easy stream URL addition
- âœ… Customizable schedule

## ğŸš€ Deployment Checklist

- [ ] Add GitHub secrets (FIREBASE_URL, FIREBASE_AUTH)
- [ ] Push code to GitHub
- [ ] Enable GitHub Actions
- [ ] Run manual test
- [ ] Verify Firebase data
- [ ] Monitor first scheduled run

## ğŸ“ˆ Usage Statistics

- **Scraping Frequency**: Every 40 minutes (36 times/day)
- **Execution Time**: ~30-60 seconds per run
- **Data Retention**: Artifacts kept for 7 days
- **Browser**: Chromium (headless)
- **Wait Time**: 20 seconds for stream loading

## ğŸ” Security

- âœ… Secrets stored in GitHub (not in code)
- âœ… .env file excluded from git
- âœ… No hardcoded credentials
- âœ… Firebase auth token optional

## ğŸ“ Configuration

### Add Stream URLs
Edit `scraper_playwright.py`:
```python
STREAM_URLS = [
    {
        "url": "https://your-stream.com",
        "name": "Stream Name",
        "title": "Stream Title"
    }
]
```

### Change Schedule
Edit `.github/workflows/scrape-streams.yml`:
```yaml
schedule:
  - cron: '*/40 * * * *'  # Every 40 minutes
```

### Adjust Wait Times
Edit `scraper_playwright.py`:
```python
time.sleep(20)  # Increase if streams load slowly
```

## ğŸ“ Learning Resources

- **Playwright Docs**: https://playwright.dev/python/
- **GitHub Actions**: https://docs.github.com/actions
- **Firebase RTDB**: https://firebase.google.com/docs/database
- **Cron Syntax**: https://crontab.guru/

## ğŸ†˜ Support

See documentation files:
- **Quick Setup**: [QUICKSTART.md](QUICKSTART.md)
- **Testing**: [TESTING.md](TESTING.md)
- **Deployment**: [DEPLOYMENT.md](DEPLOYMENT.md)
- **Main Docs**: [README.md](README.md)

## ğŸ‰ Success Criteria

Your scraper is working when:
1. âœ… Workflow runs every 40 minutes
2. âœ… Logs show "Found m3u8" messages
3. âœ… Firebase contains updated data
4. âœ… Artifacts are generated
5. âœ… No error messages in logs

## ğŸ”® Future Enhancements

Potential improvements:
- Add multiple stream sources
- Implement retry logic for failed scrapes
- Add Discord/Slack notifications
- Store historical data
- Add stream quality detection
- Implement rate limiting
- Add proxy support
- Create web dashboard

## ğŸ“Š Monitoring

### Check Workflow Status
```
GitHub â†’ Actions â†’ Scrape Cricket Streams
```

### View Firebase Data
```
https://cricket-stream-portal-default-rtdb.firebaseio.com/.json
```

### Download Results
```
Actions â†’ Completed Run â†’ Artifacts â†’ Download
```

---

**Built with**: Python, Playwright, GitHub Actions, Firebase
**License**: Use as needed
**Maintenance**: Update stream URLs as needed
